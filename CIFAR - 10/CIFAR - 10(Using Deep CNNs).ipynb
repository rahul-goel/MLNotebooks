{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR - 10",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a5d275d24b04f75a126047188922e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65b94898b39e4e5e996b918e40479965",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87b2709a89fa4725b44c21067c6126d2",
              "IPY_MODEL_c4d2798507b24e32acee40d5f39753fb"
            ]
          }
        },
        "65b94898b39e4e5e996b918e40479965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87b2709a89fa4725b44c21067c6126d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e52e0085013449bf81ccb25a170196df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5778bc5ac4dc4752a13ad0e902d6468c"
          }
        },
        "c4d2798507b24e32acee40d5f39753fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e72f57468c9442c285a2bf6cc9869af0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 31982897.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26326cfd0e654f09b167756b903f1a8f"
          }
        },
        "e52e0085013449bf81ccb25a170196df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5778bc5ac4dc4752a13ad0e902d6468c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e72f57468c9442c285a2bf6cc9869af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26326cfd0e654f09b167756b903f1a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V8qGUicyesr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_9GZgQdJbqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "3a5d275d24b04f75a126047188922e00",
            "65b94898b39e4e5e996b918e40479965",
            "87b2709a89fa4725b44c21067c6126d2",
            "c4d2798507b24e32acee40d5f39753fb",
            "e52e0085013449bf81ccb25a170196df",
            "5778bc5ac4dc4752a13ad0e902d6468c",
            "e72f57468c9442c285a2bf6cc9869af0",
            "26326cfd0e654f09b167756b903f1a8f"
          ]
        },
        "outputId": "53dad98e-4d70-4903-cf87-2f5e4561889b"
      },
      "source": [
        "data_train = torchvision.datasets.CIFAR10('.', train = True, transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                                                                             transforms.RandomAffine(degrees = (-10, 10), translate = (0.0, 0.1)),\n",
        "                                                                                             transforms.ToTensor()]), download = True)\n",
        "data_test = torchvision.datasets.CIFAR10('.', train = True, transform = transforms.ToTensor(), download = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a5d275d24b04f75a126047188922e00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRuPnd1zKJey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataloader(dataset, pct, batch_size):\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(pct * dataset_size))\n",
        "    train_indices, valid_indices = indices[split:], indices[:split]\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler)\n",
        "    valid_loader = DataLoader(dataset, batch_size = batch_size, sampler = valid_sampler)\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmRG-7rWKNob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, valid_loader = make_dataloader(data_train, 0.2, 256)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBEYTRYrKPG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            # Conv Block 1\n",
        "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.BatchNorm2d(32).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2).cuda(),\n",
        "\n",
        "            # Conv Block 2\n",
        "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.BatchNorm2d(128).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2).cuda(),\n",
        "\n",
        "            # Conv Block 3\n",
        "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.BatchNorm2d(256).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride= 2).cuda(),\n",
        "\n",
        "            # Conv Block 4\n",
        "            nn.Conv2d(in_channels = 256,  out_channels = 512, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.BatchNorm2d(512).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1).cuda(),\n",
        "            nn.BatchNorm2d(512).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride= 2).cuda()\n",
        "        )\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p = 0.3).cuda(),\n",
        "            nn.Linear(2048, 2048).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Linear(2048, 1024).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Dropout(p = 0.3).cuda(),\n",
        "            nn.Linear(1024, 1024).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Dropout(p = 0.3).cuda(),\n",
        "            nn.Linear(1024, 100).cuda(),\n",
        "            nn.ReLU().cuda(),\n",
        "            nn.Dropout(p = 0.3),\n",
        "            nn.Linear(100, 10).cuda()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "         x = self.conv_layer(x)\n",
        "         x = x.view(x.shape[0], -1)\n",
        "         x = self.fc_layer(x)\n",
        "         return x"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTgwTLZWNQ3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Network()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxbqI7yoNRn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpVEPbFTNYmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingloss = []\n",
        "trainingacc = []\n",
        "validationloss = []\n",
        "validationacc = []"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqx7SX5Na7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, y):\n",
        "    _, preds = torch.max(output, dim = 1)\n",
        "    return torch.tensor(torch.sum(preds == y).item() / len(preds))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69iSCNj7Nesv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea8e5a9-67e5-4a27-a52f-a431606e1bad"
      },
      "source": [
        "use_cuda = True\n",
        "use_cuda, torch.cuda.is_available()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM92E_AlUxgJ",
        "colab_type": "text"
      },
      "source": [
        "Trained for 20 epochs with learning rate of 1e-3\n",
        "Trained for 20 epochs with learning rate of 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8d19MFqNk5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "027c84fc-102f-447c-f94f-c51ff7396d5d"
      },
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    train_acc = torch.tensor(0, dtype = torch.float32)\n",
        "    train_loss = torch.tensor(0, dtype = torch.float32)\n",
        "    train_cnt = torch.tensor(0, dtype = torch.float32)\n",
        "\n",
        "    model.train()\n",
        "    for (i, batch) in enumerate(train_loader):\n",
        "        # Unwrap the batch\n",
        "        X, y = batch\n",
        "        X, y = Variable(X), Variable(y)\n",
        "        # Transfer to GPU\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(output, y)\n",
        "\n",
        "        # Calculate the gradient of loss wrt the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Subtract the gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the history (NOTE that this is the batch loss and batch accuracy)\n",
        "        batch_size = X.shape[0]\n",
        "        train_cnt += batch_size\n",
        "        acc = accuracy(output, y)\n",
        "        train_loss = train_loss + loss * batch_size\n",
        "        train_acc = train_acc + acc * batch_size\n",
        "\n",
        "    train_loss = train_loss / train_cnt\n",
        "    train_acc = train_acc / train_cnt\n",
        "    trainingloss.append(train_loss)\n",
        "    trainingacc.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = torch.tensor(0, dtype = torch.float32)\n",
        "        val_acc = torch.tensor(0, dtype = torch.float32)\n",
        "        val_cnt = torch.tensor(0, dtype = torch.float32)\n",
        "\n",
        "        for (i, batch) in enumerate(valid_loader):\n",
        "            # Unwrap the batch\n",
        "            X, y = batch\n",
        "            X, y = Variable(X), Variable(y)\n",
        "            # Transfer to GPU\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                X = X.cuda()\n",
        "                y = y.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(X)\n",
        "            # Calculate the loss\n",
        "            loss = loss_func(output, y)\n",
        "            \n",
        "            # Accumulate the history\n",
        "            batch_size = X.shape[0]\n",
        "            val_cnt = val_cnt + batch_size\n",
        "            val_loss = val_loss + loss * batch_size\n",
        "            acc = accuracy(output, y)\n",
        "            val_acc = val_acc + acc * batch_size\n",
        "        \n",
        "        val_loss = val_loss / val_cnt\n",
        "        val_acc = val_acc / val_cnt\n",
        "        validationloss.append(val_loss)\n",
        "        validationacc.append(val_acc)\n",
        "    print(f\"Training Loss - {train_loss : 0.5f} Training Accuracy - {train_acc : 0.5f} Validation Loss - {val_loss : 0.5f} Validation Accuracy - {val_acc : 0.5f}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss -  0.36569 Training Accuracy -  0.88300 Validation Loss -  0.49166 Validation Accuracy -  0.84430\n",
            "Training Loss -  0.35161 Training Accuracy -  0.88722 Validation Loss -  0.48870 Validation Accuracy -  0.84570\n",
            "Training Loss -  0.35687 Training Accuracy -  0.88475 Validation Loss -  0.48301 Validation Accuracy -  0.84580\n",
            "Training Loss -  0.34708 Training Accuracy -  0.88832 Validation Loss -  0.47444 Validation Accuracy -  0.85110\n",
            "Training Loss -  0.34637 Training Accuracy -  0.88690 Validation Loss -  0.46474 Validation Accuracy -  0.85090\n",
            "Training Loss -  0.34264 Training Accuracy -  0.88893 Validation Loss -  0.46788 Validation Accuracy -  0.85040\n",
            "Training Loss -  0.33714 Training Accuracy -  0.89155 Validation Loss -  0.46284 Validation Accuracy -  0.85020\n",
            "Training Loss -  0.33821 Training Accuracy -  0.88963 Validation Loss -  0.46497 Validation Accuracy -  0.85190\n",
            "Training Loss -  0.33620 Training Accuracy -  0.89157 Validation Loss -  0.45748 Validation Accuracy -  0.85440\n",
            "Training Loss -  0.33045 Training Accuracy -  0.89340 Validation Loss -  0.45779 Validation Accuracy -  0.85400\n",
            "Training Loss -  0.32836 Training Accuracy -  0.89522 Validation Loss -  0.45789 Validation Accuracy -  0.85390\n",
            "Training Loss -  0.32753 Training Accuracy -  0.89328 Validation Loss -  0.45323 Validation Accuracy -  0.85660\n",
            "Training Loss -  0.32480 Training Accuracy -  0.89412 Validation Loss -  0.45274 Validation Accuracy -  0.85250\n",
            "Training Loss -  0.32573 Training Accuracy -  0.89487 Validation Loss -  0.44841 Validation Accuracy -  0.85560\n",
            "Training Loss -  0.31976 Training Accuracy -  0.89597 Validation Loss -  0.45763 Validation Accuracy -  0.85340\n",
            "Training Loss -  0.32569 Training Accuracy -  0.89498 Validation Loss -  0.44974 Validation Accuracy -  0.85470\n",
            "Training Loss -  0.31999 Training Accuracy -  0.89535 Validation Loss -  0.44985 Validation Accuracy -  0.85700\n",
            "Training Loss -  0.32045 Training Accuracy -  0.89725 Validation Loss -  0.44803 Validation Accuracy -  0.85870\n",
            "Training Loss -  0.31758 Training Accuracy -  0.89650 Validation Loss -  0.43710 Validation Accuracy -  0.85900\n",
            "Training Loss -  0.31380 Training Accuracy -  0.89755 Validation Loss -  0.45802 Validation Accuracy -  0.85380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weTL6CWkb8jJ",
        "colab_type": "text"
      },
      "source": [
        "Compared to previous experiments this seems decent enought. Now let us take the same model and the same training process and train on the full dataset so that we dont waste data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxXzluzycI_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, valid_loader = make_dataloader(data_train, 0, 256)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vD6CLsNdciIS",
        "colab": {}
      },
      "source": [
        "model = Network()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7crOoshRciIl",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-oTiAu8-ciIv",
        "colab": {}
      },
      "source": [
        "trainingloss = []\n",
        "trainingacc = []\n",
        "validationloss = []\n",
        "validationacc = []"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rk-IrMn8ciI1",
        "colab": {}
      },
      "source": [
        "def accuracy(output, y):\n",
        "    _, preds = torch.max(output, dim = 1)\n",
        "    return torch.tensor(torch.sum(preds == y).item() / len(preds))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWtWjRTgciI5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fedd28dd-8d57-4510-aefe-bcb960589332"
      },
      "source": [
        "use_cuda = True\n",
        "use_cuda, torch.cuda.is_available()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zTwDVd3eciI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "34a78c35-b5ec-4a6f-8d9f-688a71501379"
      },
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    train_acc = torch.tensor(0, dtype = torch.float32)\n",
        "    train_loss = torch.tensor(0, dtype = torch.float32)\n",
        "    train_cnt = torch.tensor(0, dtype = torch.float32)\n",
        "\n",
        "    model.train()\n",
        "    for (i, batch) in enumerate(train_loader):\n",
        "        # Unwrap the batch\n",
        "        X, y = batch\n",
        "        X, y = Variable(X), Variable(y)\n",
        "        # Transfer to GPU\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(output, y)\n",
        "\n",
        "        # Calculate the gradient of loss wrt the params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Subtract the gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the history (NOTE that this is the batch loss and batch accuracy)\n",
        "        batch_size = X.shape[0]\n",
        "        train_cnt += batch_size\n",
        "        acc = accuracy(output, y)\n",
        "        train_loss = train_loss + loss * batch_size\n",
        "        train_acc = train_acc + acc * batch_size\n",
        "\n",
        "    train_loss = train_loss / train_cnt\n",
        "    train_acc = train_acc / train_cnt\n",
        "    trainingloss.append(train_loss)\n",
        "    trainingacc.append(train_acc)\n",
        "    print(f\"Training Loss - {train_loss : 0.5f} Training Accuracy - {train_acc : 0.5f}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss -  0.32279 Training Accuracy -  0.89446\n",
            "Training Loss -  0.31562 Training Accuracy -  0.89674\n",
            "Training Loss -  0.30873 Training Accuracy -  0.89918\n",
            "Training Loss -  0.30521 Training Accuracy -  0.90114\n",
            "Training Loss -  0.30359 Training Accuracy -  0.90146\n",
            "Training Loss -  0.29878 Training Accuracy -  0.90232\n",
            "Training Loss -  0.29378 Training Accuracy -  0.90490\n",
            "Training Loss -  0.29339 Training Accuracy -  0.90382\n",
            "Training Loss -  0.29249 Training Accuracy -  0.90594\n",
            "Training Loss -  0.28693 Training Accuracy -  0.90600\n",
            "Training Loss -  0.29170 Training Accuracy -  0.90472\n",
            "Training Loss -  0.28490 Training Accuracy -  0.90760\n",
            "Training Loss -  0.28460 Training Accuracy -  0.90742\n",
            "Training Loss -  0.28473 Training Accuracy -  0.90698\n",
            "Training Loss -  0.28057 Training Accuracy -  0.90796\n",
            "Training Loss -  0.27763 Training Accuracy -  0.90886\n",
            "Training Loss -  0.27889 Training Accuracy -  0.90812\n",
            "Training Loss -  0.28296 Training Accuracy -  0.90744\n",
            "Training Loss -  0.27942 Training Accuracy -  0.90900\n",
            "Training Loss -  0.27309 Training Accuracy -  0.91046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc8wYpKtcYDz",
        "colab_type": "text"
      },
      "source": [
        "Time to find the results on the official test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvAVpYgeWChE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = DataLoader(data_test, batch_size = 256)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNG3mcGhWVjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10584e08-e885-428b-823c-84ab71f0dab7"
      },
      "source": [
        "test_acc = torch.tensor(0, dtype = torch.float32)\n",
        "test_cnt = torch.tensor(0, dtype = torch.float32)\n",
        "for batch in test_loader:\n",
        "    X, y = batch\n",
        "    X = Variable(X)\n",
        "    y = Variable(y)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        X = X.cuda()\n",
        "        y = y.cuda()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        batch_size = X.shape[0]\n",
        "        output = model(X)\n",
        "        acc = accuracy(output, y)\n",
        "        test_acc += acc * batch_size\n",
        "        test_cnt += batch_size\n",
        "test_acc = test_acc / test_cnt\n",
        "print(f\"Test accurary - {test_acc.item() : 0.5f}\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accurary -  0.93168\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}